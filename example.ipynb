{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a62913d",
   "metadata": {},
   "source": [
    "# Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ce3f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install coderbot_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7470de1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "562665a45bbb4753ace24c886b361175",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "RobotSim(debugDraw=True, mapData={'map': [{'type': 'rectangle', 'x': 400, 'y': 0, 'width': 800, 'height': 30, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<_GatheringFuture pending>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{'lidar': {'angles': [-3.141592653589793, -2.9249310912732556, -2.708269528956718, -2.4916079666401805, -2.2749464043236434, -2.058284842007106, -1.8416232796905683, -1.624961717374031, -1.4083001550574934, -1.191638592740956, -0.9749770304244185, -0.7583154681078814, -0.5416539057913434, -0.3249923434748059, -0.10833078115826877, 0.10833078115826833, 0.3249923434748063, 0.5416539057913439, 0.758315468107881, 0.9749770304244185, 1.191638592740956, 1.4083001550574936, 1.6249617173740303, 1.8416232796905678, 2.0582848420071063, 2.274946404323644, 2.4916079666401814, 2.708269528956718, 2.9249310912732556, 3.141592653589793], 'hitPoints': [{'x': 309.6603199355011, 'y': 268.740277779854}, {'x': 326.7384713415892, 'y': 236.47674936329247}, {'x': 341.8540655138813, 'y': 207.92082486568503}, {'x': 139.52353151774497, 'y': 15}, {'x': 344.677126601384, 'y': 117.29823329543206}, {'x': 379.81643179307133, 'y': 92.38674290739414}, {'x': 402.86251729931735, 'y': 15}, {'x': 459.55576052275296, 'y': 15}, {'x': 514.9117656928847, 'y': 15}, {'x': 500.41136664737076, 'y': 200.728904111213}, {'x': 519.4260141709769, 'y': 200.728904111213}, {'x': 499.8787865517835, 'y': 243.5759783517923}, {'x': 500.89894521244196, 'y': 252.1424607006419}, {'x': 501.73509840799875, 'y': 259.1638112678638}, {'x': 502.4975511346476, 'y': 265.56628382096085}, {'x': 503.26343479204843, 'y': 271.9975666060934}, {'x': 504.11131420228776, 'y': 279.11738461271466}, {'x': 505.1572383202561, 'y': 287.90022481232506}, {'x': 496.54349957160275, 'y': 290.7452255632997}, {'x': 494.5695018520001, 'y': 300.0910385284819}, {'x': 493.8181809602287, 'y': 320.20400315981897}, {'x': 491.5787020788722, 'y': 380.1551638777819}, {'x': 456.43714686271875, 'y': 580}, {'x': 386.89232216289014, 'y': 580}, {'x': 389.986400408183, 'y': 425.91121690389946}, {'x': 348.37126356543246, 'y': 415.83324801505677}, {'x': 234.21627069644074, 'y': 450.4970066686991}, {'x': 322.2470610023704, 'y': 338.6308969356244}, {'x': 20, 'y': 368.52204941628537}, {'x': 309.6603199355011, 'y': 268.740277779854}], 'labels': ['Obstacle', 'Obstacle', 'Obstacle', 'Rectangle Body', 'Pushable Box', 'Pushable Box', 'Rectangle Body', 'Rectangle Body', 'Rectangle Body', 'Pushable Box', 'Pushable Box', 'Obstacle', 'Obstacle', 'Obstacle', 'Obstacle', 'Obstacle', 'Obstacle', 'Obstacle', 'Obstacle', 'Obstacle', 'Obstacle', 'Obstacle', 'Rectangle Body', 'Rectangle Body', 'Goal', 'Goal', 'Obstacle', 'Pushable Box', 'Rectangle Body', 'Obstacle']}}\n"
     ]
    }
   ],
   "source": [
    "from coderbot_sim import RobotSim, example_maps\n",
    "from IPython.display import display\n",
    "import asyncio\n",
    "\n",
    "widget = RobotSim(example_maps.gen_simple_map(), debugDraw=True, show_controls=True)\n",
    "display(widget)\n",
    "\n",
    "async def my_sim():\n",
    "    print(widget.sensor())\n",
    "    await widget.step(0.5, forward=True)\n",
    "    print(widget.sensor())\n",
    "\n",
    "asyncio.gather(my_sim(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c571a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "widget.move(**{\n",
    "  \"forward\": False,\n",
    "  \"backward\": True\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49a2385",
   "metadata": {},
   "source": [
    "# Simple _mock_ training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32f9b236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bab09295d1d54224b199e5584e1cfdd7",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "RobotSim(debugDraw=True, mapData={'map': [{'type': 'rectangle', 'x': 400, 'y': 0, 'width': 800, 'height': 30, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: total reward = 50.00\n",
      "Episode 2: total reward = 50.00\n",
      "Episode 3: total reward = 50.00\n",
      "Episode 4: total reward = 50.00\n",
      "Episode 5: total reward = 50.00\n"
     ]
    }
   ],
   "source": [
    "from coderbot_sim import RobotSim, example_maps\n",
    "from IPython.display import display\n",
    "import asyncio\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "ACTIONS = [\"forward\", \"left\", \"right\"]\n",
    "\n",
    "q_table = {}\n",
    "alpha = 0.1  # learning rate\n",
    "gamma = 0.9  # discount factor\n",
    "epsilon = 0.1  # exploration rate\n",
    "\n",
    "def get_state(lidar):\n",
    "    # Quantize distances into bins\n",
    "    distances = [np.linalg.norm(p) for p in lidar.get(\"hitPoints\", [])[:8]]\n",
    "    # Change heuristic based on hitBodies; Goal > Pushable Box > Obstacle > Wall\n",
    "    bins = np.digitize(distances, [50, 100, 200])\n",
    "    return tuple(bins)\n",
    "\n",
    "def choose_action(state):\n",
    "    if random.random() < epsilon or state not in q_table:\n",
    "        return random.choice(ACTIONS)\n",
    "    return max(q_table[state], key=q_table[state].get)\n",
    "\n",
    "async def take_action(action):\n",
    "    if action == \"forward\":\n",
    "        await widget.step(0.1, forward=True)\n",
    "    elif action == \"left\":\n",
    "        await widget.step(0.2, left=True)\n",
    "    elif action == \"right\":\n",
    "        await widget.step(0.2, right=True)\n",
    "\n",
    "async def train_q_learning(episodes=5):\n",
    "    for ep in range(episodes):\n",
    "        total_reward = 0\n",
    "        for _ in range(50):\n",
    "            data = widget.sensor()\n",
    "            lidar = data.get(\"lidar\", {})\n",
    "            state = get_state(lidar)\n",
    "\n",
    "            action = choose_action(state)\n",
    "            await take_action(action)\n",
    "\n",
    "            next_data = widget.sensor()\n",
    "            next_state = get_state(next_data.get(\"lidar\", {}))\n",
    "\n",
    "            # Reward: penalize close walls\n",
    "            distances = [np.linalg.norm(p) for p in lidar.get(\"hitPoints\", [])]\n",
    "            reward = -np.sum(np.array(distances) < 50) * 0.1 + 1.0\n",
    "\n",
    "            # Update Q-table\n",
    "            q_table.setdefault(state, {a: 0 for a in ACTIONS})\n",
    "            q_table.setdefault(next_state, {a: 0 for a in ACTIONS})\n",
    "\n",
    "            old_value = q_table[state][action]\n",
    "            next_max = max(q_table[next_state].values())\n",
    "            q_table[state][action] = old_value + alpha * (reward + gamma * next_max - old_value)\n",
    "\n",
    "            total_reward += reward\n",
    "\n",
    "        widget.reset()\n",
    "\n",
    "        print(f\"Episode {ep+1}: total reward = {total_reward:.2f}\")\n",
    "\n",
    "# Create and show robot\n",
    "widget = RobotSim(example_maps.gen_simple_map(), debugDraw=True, show_controls=True)\n",
    "display(widget)\n",
    "\n",
    "# ✅ Run in Jupyter\n",
    "await train_q_learning()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
